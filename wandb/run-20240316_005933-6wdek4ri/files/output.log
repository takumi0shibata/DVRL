load data from data/cross_prompt_attributes/7/...
Loading embedding from cache...
Selected 40 samples.
Selected sample indices: [1414, 1248, 631, 740, 1363, 872, 51, 394, 1466, 1166, 838, 1306, 370, 628, 999, 72, 364, 945, 632, 1468, 1082, 675, 503, 1329, 1362, 1033, 767, 1453, 929, 1010, 1336, 35, 1346, 458, 1424, 62, 664, 948, 1272, 330]
================================
x_dev shape: (40,)
y_dev shape: (40,)
================================
x_test shape: (1529,)
y_test shape: (1529,)
================================
/home/takumi/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
Training: 100%|███████████████████████████████████████| 2/2 [00:01<00:00,  1.74batch/s, loss=0.0665]
Evaluation:  10%|███▊                                 | 5/48 [00:00<00:05,  7.30batch/s, loss=0.015]


Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.50batch/s, loss=0.0168]
Training:  50%|███████████████████▌                   | 1/2 [00:00<00:00,  4.01batch/s, loss=0.0484]
[0.29636912]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.78batch/s, loss=0.0421]


Evaluation:  90%|███████████████████████████████▎   | 43/48 [00:05<00:00,  7.63batch/s, loss=0.0141]
[0.4811855]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.51batch/s, loss=0.0143]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.47batch/s, loss=0.0324]


Evaluation:  73%|█████████████████████████▌         | 35/48 [00:04<00:01,  7.46batch/s, loss=0.0136]
[0.52001835]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.41batch/s, loss=0.0139]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.60batch/s, loss=0.0281]


Evaluation:  92%|████████████████████████████████   | 44/48 [00:05<00:00,  7.60batch/s, loss=0.0137]
[0.53202353]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.51batch/s, loss=0.0137]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.75batch/s, loss=0.0236]


Evaluation:  77%|██████████████████████████▉        | 37/48 [00:04<00:01,  7.60batch/s, loss=0.0138]
[0.55408342]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.50batch/s, loss=0.0139]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.53batch/s, loss=0.0184]



Evaluation:  92%|████████████████████████████████   | 44/48 [00:05<00:00,  7.61batch/s, loss=0.0143]
[0.56360398]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.42batch/s, loss=0.0142]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.62batch/s, loss=0.0159]


Evaluation:  77%|██████████████████████████▉        | 37/48 [00:05<00:01,  7.50batch/s, loss=0.0147]
[0.57749288]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.46batch/s, loss=0.0148]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.68batch/s, loss=0.0144]



Evaluation:  92%|████████████████████████████████   | 44/48 [00:05<00:00,  7.55batch/s, loss=0.0157]
[0.60433599]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.45batch/s, loss=0.0156]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.63batch/s, loss=0.0102]


Evaluation:  77%|██████████████████████████▉        | 37/48 [00:04<00:01,  7.57batch/s, loss=0.0168]
[0.61539371]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.50batch/s, loss=0.0172]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.71batch/s, loss=0.00815]



Evaluation:  94%|████████████████████████████████▊  | 45/48 [00:06<00:00,  7.59batch/s, loss=0.0184]
[0.62116086]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.47batch/s, loss=0.0184]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.75batch/s, loss=0.00736]


Evaluation:  79%|███████████████████████████▋       | 38/48 [00:05<00:01,  7.61batch/s, loss=0.0181]
[0.63281675]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.48batch/s, loss=0.0188]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.64batch/s, loss=0.00661]



Evaluation:  77%|██████████████████████████▉        | 37/48 [00:05<00:01,  7.43batch/s, loss=0.0176]
[0.64628734]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.42batch/s, loss=0.0184]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.66batch/s, loss=0.00527]


Evaluation:  79%|███████████████████████████▋       | 38/48 [00:05<00:01,  7.64batch/s, loss=0.0168]
[0.66151719]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.52batch/s, loss=0.0177]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.78batch/s, loss=0.00416]



Evaluation:  94%|█████████████████████████████████▊  | 45/48 [00:06<00:00,  7.57batch/s, loss=0.017]
[0.67302415]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.46batch/s, loss=0.0171]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.85batch/s, loss=0.00389]


Evaluation:  81%|████████████████████████████▍      | 39/48 [00:05<00:01,  7.47batch/s, loss=0.0157]
[0.67980986]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.43batch/s, loss=0.0167]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.82batch/s, loss=0.00352]



Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  8.16batch/s, loss=0.0165]
[0.68518984]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.49batch/s, loss=0.0165]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.66batch/s, loss=0.00339]


Evaluation:  81%|████████████████████████████▍      | 39/48 [00:05<00:01,  7.48batch/s, loss=0.0155]
[0.68406209]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.38batch/s, loss=0.0165]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.73batch/s, loss=0.00283]



Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.47batch/s, loss=0.0165]
[0.68304986]
Epoch 19/30
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.43batch/s, loss=0.00243]


Evaluation:  81%|████████████████████████████▍      | 39/48 [00:05<00:01,  7.42batch/s, loss=0.0153]
[0.68244956]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.41batch/s, loss=0.0164]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.73batch/s, loss=0.00305]



Evaluation:  98%|██████████████████████████████████▎| 47/48 [00:06<00:00,  7.52batch/s, loss=0.0163]
[0.67959626]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.44batch/s, loss=0.0163]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.58batch/s, loss=0.00289]


Evaluation:  81%|████████████████████████████▍      | 39/48 [00:05<00:01,  7.53batch/s, loss=0.0153]
[0.6752793]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.41batch/s, loss=0.0164]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.63batch/s, loss=0.00285]



Evaluation:  98%|██████████████████████████████████▎| 47/48 [00:06<00:00,  7.54batch/s, loss=0.0165]
[0.67209454]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.39batch/s, loss=0.0166]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.79batch/s, loss=0.00258]


Evaluation:  81%|████████████████████████████▍      | 39/48 [00:05<00:01,  7.56batch/s, loss=0.0156]
[0.6699136]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.43batch/s, loss=0.0167]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.75batch/s, loss=0.00209]



Evaluation:  98%|██████████████████████████████████▎| 47/48 [00:06<00:00,  7.55batch/s, loss=0.0167]
[0.6691011]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.42batch/s, loss=0.0168]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.71batch/s, loss=0.00221]


Evaluation:  81%|████████████████████████████▍      | 39/48 [00:05<00:01,  7.50batch/s, loss=0.0156]
[0.67032356]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.41batch/s, loss=0.0167]
Training: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  3.78batch/s, loss=0.0025]



Evaluation:  98%|██████████████████████████████████▎| 47/48 [00:06<00:00,  7.56batch/s, loss=0.0164]
[0.67191636]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.40batch/s, loss=0.0165]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.73batch/s, loss=0.00236]


Evaluation:  83%|█████████████████████████████▏     | 40/48 [00:05<00:01,  7.54batch/s, loss=0.0154]
[0.67492302]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.47batch/s, loss=0.0163]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.58batch/s, loss=0.00232]



Evaluation:  98%|██████████████████████████████████▎| 47/48 [00:06<00:00,  7.57batch/s, loss=0.0161]
[0.67758488]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.41batch/s, loss=0.0161]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.65batch/s, loss=0.00217]


Evaluation:  83%|█████████████████████████████▏     | 40/48 [00:05<00:01,  7.57batch/s, loss=0.0151]
[0.67964185]
Evaluation: 100%|███████████████████████████████████| 48/48 [00:06<00:00,  7.47batch/s, loss=0.0161]
Training: 100%|██████████████████████████████████████| 2/2 [00:00<00:00,  3.66batch/s, loss=0.00213]



Evaluation: 100%|████████████████████████████████████| 48/48 [00:06<00:00,  7.49batch/s, loss=0.016]
[0.68105082]